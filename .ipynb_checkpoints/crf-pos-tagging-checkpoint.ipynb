{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLEGOOO\n",
      "LLEGOOO\n",
      "[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')]\n",
      "Tagged sentences:  6030\n",
      "Tagged words: 192686\n",
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n",
      "Tagged sentences:  57340\n",
      "Tagged words: 1161192\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.corpus import brown\n",
    "nltk.download('cess_esp')\n",
    "print(\"LLEGOOO\")\n",
    "nltk.download('brown')\n",
    "print(\"LLEGOOO\")\n",
    "tagged_sentences = cess_esp.tagged_sents()\n",
    "tagged_sentences1 = brown.tagged_sents()#[:6030]\n",
    "#print('a random sentence: \\n-> {}'.format(random.choice(sentences)))\n",
    " \n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(cess_esp.tagged_words()))\n",
    "\n",
    "print(tagged_sentences1[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences1))\n",
    "print(\"Tagged words:\", len(brown.tagged_words()))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    print (sentence)\n",
    "    print (index)\n",
    "    \n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "57280\n",
      "[{'word': 'The', 'is_first': True, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'T', 'prefix-2': 'Th', 'prefix-3': 'The', 'suffix-1': 'e', 'suffix-2': 'he', 'suffix-3': 'The', 'prev_word': '', 'next_word': 'Fulton', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Fulton', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'F', 'prefix-2': 'Fu', 'prefix-3': 'Ful', 'suffix-1': 'n', 'suffix-2': 'on', 'suffix-3': 'ton', 'prev_word': 'The', 'next_word': 'County', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'County', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'C', 'prefix-2': 'Co', 'prefix-3': 'Cou', 'suffix-1': 'y', 'suffix-2': 'ty', 'suffix-3': 'nty', 'prev_word': 'Fulton', 'next_word': 'Grand', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Grand', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'G', 'prefix-2': 'Gr', 'prefix-3': 'Gra', 'suffix-1': 'd', 'suffix-2': 'nd', 'suffix-3': 'and', 'prev_word': 'County', 'next_word': 'Jury', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Jury', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'J', 'prefix-2': 'Ju', 'prefix-3': 'Jur', 'suffix-1': 'y', 'suffix-2': 'ry', 'suffix-3': 'ury', 'prev_word': 'Grand', 'next_word': 'said', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'said', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 's', 'prefix-2': 'sa', 'prefix-3': 'sai', 'suffix-1': 'd', 'suffix-2': 'id', 'suffix-3': 'aid', 'prev_word': 'Jury', 'next_word': 'Friday', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Friday', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'F', 'prefix-2': 'Fr', 'prefix-3': 'Fri', 'suffix-1': 'y', 'suffix-2': 'ay', 'suffix-3': 'day', 'prev_word': 'said', 'next_word': 'an', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'an', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'a', 'prefix-2': 'an', 'prefix-3': 'an', 'suffix-1': 'n', 'suffix-2': 'an', 'suffix-3': 'an', 'prev_word': 'Friday', 'next_word': 'investigation', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'investigation', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'i', 'prefix-2': 'in', 'prefix-3': 'inv', 'suffix-1': 'n', 'suffix-2': 'on', 'suffix-3': 'ion', 'prev_word': 'an', 'next_word': 'of', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'of', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'o', 'prefix-2': 'of', 'prefix-3': 'of', 'suffix-1': 'f', 'suffix-2': 'of', 'suffix-3': 'of', 'prev_word': 'investigation', 'next_word': \"Atlanta's\", 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': \"Atlanta's\", 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'A', 'prefix-2': 'At', 'prefix-3': 'Atl', 'suffix-1': 's', 'suffix-2': \"'s\", 'suffix-3': \"a's\", 'prev_word': 'of', 'next_word': 'recent', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'recent', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'r', 'prefix-2': 're', 'prefix-3': 'rec', 'suffix-1': 't', 'suffix-2': 'nt', 'suffix-3': 'ent', 'prev_word': \"Atlanta's\", 'next_word': 'primary', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'primary', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'p', 'prefix-2': 'pr', 'prefix-3': 'pri', 'suffix-1': 'y', 'suffix-2': 'ry', 'suffix-3': 'ary', 'prev_word': 'recent', 'next_word': 'election', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'election', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'e', 'prefix-2': 'el', 'prefix-3': 'ele', 'suffix-1': 'n', 'suffix-2': 'on', 'suffix-3': 'ion', 'prev_word': 'primary', 'next_word': 'produced', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'produced', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'p', 'prefix-2': 'pr', 'prefix-3': 'pro', 'suffix-1': 'd', 'suffix-2': 'ed', 'suffix-3': 'ced', 'prev_word': 'election', 'next_word': '``', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': '``', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': '`', 'prefix-2': '``', 'prefix-3': '``', 'suffix-1': '`', 'suffix-2': '``', 'suffix-3': '``', 'prev_word': 'produced', 'next_word': 'no', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'no', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'n', 'prefix-2': 'no', 'prefix-3': 'no', 'suffix-1': 'o', 'suffix-2': 'no', 'suffix-3': 'no', 'prev_word': '``', 'next_word': 'evidence', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'evidence', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'e', 'prefix-2': 'ev', 'prefix-3': 'evi', 'suffix-1': 'e', 'suffix-2': 'ce', 'suffix-3': 'nce', 'prev_word': 'no', 'next_word': \"''\", 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': \"''\", 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': \"'\", 'prefix-2': \"''\", 'prefix-3': \"''\", 'suffix-1': \"'\", 'suffix-2': \"''\", 'suffix-3': \"''\", 'prev_word': 'evidence', 'next_word': 'that', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'that', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 't', 'prefix-2': 'th', 'prefix-3': 'tha', 'suffix-1': 't', 'suffix-2': 'at', 'suffix-3': 'hat', 'prev_word': \"''\", 'next_word': 'any', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'any', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'a', 'prefix-2': 'an', 'prefix-3': 'any', 'suffix-1': 'y', 'suffix-2': 'ny', 'suffix-3': 'any', 'prev_word': 'that', 'next_word': 'irregularities', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'irregularities', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'i', 'prefix-2': 'ir', 'prefix-3': 'irr', 'suffix-1': 's', 'suffix-2': 'es', 'suffix-3': 'ies', 'prev_word': 'any', 'next_word': 'took', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'took', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 't', 'prefix-2': 'to', 'prefix-3': 'too', 'suffix-1': 'k', 'suffix-2': 'ok', 'suffix-3': 'ook', 'prev_word': 'irregularities', 'next_word': 'place', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'place', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'p', 'prefix-2': 'pl', 'prefix-3': 'pla', 'suffix-1': 'e', 'suffix-2': 'ce', 'suffix-3': 'ace', 'prev_word': 'took', 'next_word': '.', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': '.', 'is_first': False, 'is_last': True, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': '.', 'prefix-2': '.', 'prefix-3': '.', 'suffix-1': '.', 'suffix-2': '.', 'suffix-3': '.', 'prev_word': 'place', 'next_word': '', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}]\n",
      "['AT', 'NP-TL', 'NN-TL', 'JJ-TL', 'NN-TL', 'VBD', 'NR', 'AT', 'NN', 'IN', 'NP$', 'JJ', 'NN', 'NN', 'VBD', '``', 'AT', 'NN', \"''\", 'CS', 'DTI', 'NNS', 'VBD', 'NN', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "5970\n",
      "[{'word': 'El', 'is_first': True, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'E', 'prefix-2': 'El', 'prefix-3': 'El', 'suffix-1': 'l', 'suffix-2': 'El', 'suffix-3': 'El', 'prev_word': '', 'next_word': 'grupo', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'grupo', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'g', 'prefix-2': 'gr', 'prefix-3': 'gru', 'suffix-1': 'o', 'suffix-2': 'po', 'suffix-3': 'upo', 'prev_word': 'El', 'next_word': 'estatal', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'estatal', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'e', 'prefix-2': 'es', 'prefix-3': 'est', 'suffix-1': 'l', 'suffix-2': 'al', 'suffix-3': 'tal', 'prev_word': 'grupo', 'next_word': 'Electricité_de_France', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Electricité_de_France', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'E', 'prefix-2': 'El', 'prefix-3': 'Ele', 'suffix-1': 'e', 'suffix-2': 'ce', 'suffix-3': 'nce', 'prev_word': 'estatal', 'next_word': '-Fpa-', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': True}, {'word': '-Fpa-', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': '-', 'prefix-2': '-F', 'prefix-3': '-Fp', 'suffix-1': '-', 'suffix-2': 'a-', 'suffix-3': 'pa-', 'prev_word': 'Electricité_de_France', 'next_word': 'EDF', 'has_hyphen': True, 'is_numeric': False, 'capitals_inside': True}, {'word': 'EDF', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': False, 'prefix-1': 'E', 'prefix-2': 'ED', 'prefix-3': 'EDF', 'suffix-1': 'F', 'suffix-2': 'DF', 'suffix-3': 'EDF', 'prev_word': '-Fpa-', 'next_word': '-Fpt-', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': True}, {'word': '-Fpt-', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': '-', 'prefix-2': '-F', 'prefix-3': '-Fp', 'suffix-1': '-', 'suffix-2': 't-', 'suffix-3': 'pt-', 'prev_word': 'EDF', 'next_word': 'anunció', 'has_hyphen': True, 'is_numeric': False, 'capitals_inside': True}, {'word': 'anunció', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'a', 'prefix-2': 'an', 'prefix-3': 'anu', 'suffix-1': 'ó', 'suffix-2': 'ió', 'suffix-3': 'ció', 'prev_word': '-Fpt-', 'next_word': 'hoy', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'hoy', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'h', 'prefix-2': 'ho', 'prefix-3': 'hoy', 'suffix-1': 'y', 'suffix-2': 'oy', 'suffix-3': 'hoy', 'prev_word': 'anunció', 'next_word': ',', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': ',', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': ',', 'prefix-2': ',', 'prefix-3': ',', 'suffix-1': ',', 'suffix-2': ',', 'suffix-3': ',', 'prev_word': 'hoy', 'next_word': 'jueves', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'jueves', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'j', 'prefix-2': 'ju', 'prefix-3': 'jue', 'suffix-1': 's', 'suffix-2': 'es', 'suffix-3': 'ves', 'prev_word': ',', 'next_word': ',', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': ',', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': ',', 'prefix-2': ',', 'prefix-3': ',', 'suffix-1': ',', 'suffix-2': ',', 'suffix-3': ',', 'prev_word': 'jueves', 'next_word': 'la', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'la', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'l', 'prefix-2': 'la', 'prefix-3': 'la', 'suffix-1': 'a', 'suffix-2': 'la', 'suffix-3': 'la', 'prev_word': ',', 'next_word': 'compra', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'compra', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'c', 'prefix-2': 'co', 'prefix-3': 'com', 'suffix-1': 'a', 'suffix-2': 'ra', 'suffix-3': 'pra', 'prev_word': 'la', 'next_word': 'del', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'del', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'd', 'prefix-2': 'de', 'prefix-3': 'del', 'suffix-1': 'l', 'suffix-2': 'el', 'suffix-3': 'del', 'prev_word': 'compra', 'next_word': '51_por_ciento', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': '51_por_ciento', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': '5', 'prefix-2': '51', 'prefix-3': '51_', 'suffix-1': 'o', 'suffix-2': 'to', 'suffix-3': 'nto', 'prev_word': 'del', 'next_word': 'de', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'de', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'd', 'prefix-2': 'de', 'prefix-3': 'de', 'suffix-1': 'e', 'suffix-2': 'de', 'suffix-3': 'de', 'prev_word': '51_por_ciento', 'next_word': 'la', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'la', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'l', 'prefix-2': 'la', 'prefix-3': 'la', 'suffix-1': 'a', 'suffix-2': 'la', 'suffix-3': 'la', 'prev_word': 'de', 'next_word': 'empresa', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'empresa', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'e', 'prefix-2': 'em', 'prefix-3': 'emp', 'suffix-1': 'a', 'suffix-2': 'sa', 'suffix-3': 'esa', 'prev_word': 'la', 'next_word': 'mexicana', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'mexicana', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'm', 'prefix-2': 'me', 'prefix-3': 'mex', 'suffix-1': 'a', 'suffix-2': 'na', 'suffix-3': 'ana', 'prev_word': 'empresa', 'next_word': 'Electricidad_Águila_de_Altamira', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Electricidad_Águila_de_Altamira', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'E', 'prefix-2': 'El', 'prefix-3': 'Ele', 'suffix-1': 'a', 'suffix-2': 'ra', 'suffix-3': 'ira', 'prev_word': 'mexicana', 'next_word': '-Fpa-', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': True}, {'word': '-Fpa-', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': '-', 'prefix-2': '-F', 'prefix-3': '-Fp', 'suffix-1': '-', 'suffix-2': 'a-', 'suffix-3': 'pa-', 'prev_word': 'Electricidad_Águila_de_Altamira', 'next_word': 'EAA', 'has_hyphen': True, 'is_numeric': False, 'capitals_inside': True}, {'word': 'EAA', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': False, 'prefix-1': 'E', 'prefix-2': 'EA', 'prefix-3': 'EAA', 'suffix-1': 'A', 'suffix-2': 'AA', 'suffix-3': 'EAA', 'prev_word': '-Fpa-', 'next_word': '-Fpt-', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': True}, {'word': '-Fpt-', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': '-', 'prefix-2': '-F', 'prefix-3': '-Fp', 'suffix-1': '-', 'suffix-2': 't-', 'suffix-3': 'pt-', 'prev_word': 'EAA', 'next_word': ',', 'has_hyphen': True, 'is_numeric': False, 'capitals_inside': True}, {'word': ',', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': ',', 'prefix-2': ',', 'prefix-3': ',', 'suffix-1': ',', 'suffix-2': ',', 'suffix-3': ',', 'prev_word': '-Fpt-', 'next_word': 'creada', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'creada', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'c', 'prefix-2': 'cr', 'prefix-3': 'cre', 'suffix-1': 'a', 'suffix-2': 'da', 'suffix-3': 'ada', 'prev_word': ',', 'next_word': 'por', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'por', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'p', 'prefix-2': 'po', 'prefix-3': 'por', 'suffix-1': 'r', 'suffix-2': 'or', 'suffix-3': 'por', 'prev_word': 'creada', 'next_word': 'el', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'el', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'e', 'prefix-2': 'el', 'prefix-3': 'el', 'suffix-1': 'l', 'suffix-2': 'el', 'suffix-3': 'el', 'prev_word': 'por', 'next_word': 'japonés', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'japonés', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'j', 'prefix-2': 'ja', 'prefix-3': 'jap', 'suffix-1': 's', 'suffix-2': 'és', 'suffix-3': 'nés', 'prev_word': 'el', 'next_word': 'Mitsubishi_Corporation', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'Mitsubishi_Corporation', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': False, 'is_all_lower': False, 'prefix-1': 'M', 'prefix-2': 'Mi', 'prefix-3': 'Mit', 'suffix-1': 'n', 'suffix-2': 'on', 'suffix-3': 'ion', 'prev_word': 'japonés', 'next_word': 'para', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': True}, {'word': 'para', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'p', 'prefix-2': 'pa', 'prefix-3': 'par', 'suffix-1': 'a', 'suffix-2': 'ra', 'suffix-3': 'ara', 'prev_word': 'Mitsubishi_Corporation', 'next_word': 'poner_en_marcha', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'poner_en_marcha', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'p', 'prefix-2': 'po', 'prefix-3': 'pon', 'suffix-1': 'a', 'suffix-2': 'ha', 'suffix-3': 'cha', 'prev_word': 'para', 'next_word': 'una', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'una', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'u', 'prefix-2': 'un', 'prefix-3': 'una', 'suffix-1': 'a', 'suffix-2': 'na', 'suffix-3': 'una', 'prev_word': 'poner_en_marcha', 'next_word': 'central', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'central', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'c', 'prefix-2': 'ce', 'prefix-3': 'cen', 'suffix-1': 'l', 'suffix-2': 'al', 'suffix-3': 'ral', 'prev_word': 'una', 'next_word': 'de', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'de', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'd', 'prefix-2': 'de', 'prefix-3': 'de', 'suffix-1': 'e', 'suffix-2': 'de', 'suffix-3': 'de', 'prev_word': 'central', 'next_word': 'gas', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'gas', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'g', 'prefix-2': 'ga', 'prefix-3': 'gas', 'suffix-1': 's', 'suffix-2': 'as', 'suffix-3': 'gas', 'prev_word': 'de', 'next_word': 'de', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': 'de', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'd', 'prefix-2': 'de', 'prefix-3': 'de', 'suffix-1': 'e', 'suffix-2': 'de', 'suffix-3': 'de', 'prev_word': 'gas', 'next_word': '495', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': '495', 'is_first': False, 'is_last': False, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': '4', 'prefix-2': '49', 'prefix-3': '495', 'suffix-1': '5', 'suffix-2': '95', 'suffix-3': '495', 'prev_word': 'de', 'next_word': 'megavatios', 'has_hyphen': False, 'is_numeric': True, 'capitals_inside': False}, {'word': 'megavatios', 'is_first': False, 'is_last': False, 'is_capitalized': False, 'is_all_caps': False, 'is_all_lower': True, 'prefix-1': 'm', 'prefix-2': 'me', 'prefix-3': 'meg', 'suffix-1': 's', 'suffix-2': 'os', 'suffix-3': 'ios', 'prev_word': '495', 'next_word': '.', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}, {'word': '.', 'is_first': False, 'is_last': True, 'is_capitalized': True, 'is_all_caps': True, 'is_all_lower': True, 'prefix-1': '.', 'prefix-2': '.', 'prefix-3': '.', 'suffix-1': '.', 'suffix-2': '.', 'suffix-3': '.', 'prev_word': 'megavatios', 'next_word': '', 'has_hyphen': False, 'is_numeric': False, 'capitals_inside': False}]\n",
      "['da0ms0', 'ncms000', 'aq0cs0', 'np00000', 'Fpa', 'np00000', 'Fpt', 'vmis3s0', 'rg', 'Fc', 'W', 'Fc', 'da0fs0', 'ncfs000', 'spcms', 'Zp', 'sps00', 'da0fs0', 'ncfs000', 'aq0fs0', 'np00000', 'Fpa', 'np00000', 'Fpt', 'Fc', 'aq0fsp', 'sps00', 'da0ms0', 'aq0ms0', 'np00000', 'sps00', 'vmn0000', 'di0fs0', 'ncfs000', 'sps00', 'ncms000', 'sps00', 'Z', 'ncmp000', 'Fp']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag.util import untag\n",
    " \n",
    "# Split the dataset for training and testing\n",
    "cutoff = int(.01 * len(tagged_sentences))\n",
    "training_sentences = tagged_sentences[:cutoff]\n",
    "test_sentences = tagged_sentences[cutoff:]\n",
    "\n",
    "cutoff1 = int(.001 * len(tagged_sentences1))\n",
    "training_sentences1 = tagged_sentences1[:cutoff]\n",
    "test_sentences1 = tagged_sentences1[cutoff:]\n",
    " \n",
    "def transform_to_dataset(tagged_sentences1):\n",
    "    X, y = [], []\n",
    " \n",
    "    for tagged in tagged_sentences1:\n",
    "        X.append([features(untag(tagged), index) for index in range(len(tagged))])\n",
    "        y.append([tag for _, tag in tagged])\n",
    " \n",
    "    return X, y\n",
    "\n",
    "X_train1, y_train1 = transform_to_dataset(training_sentences1)\n",
    "X_test1, y_test1 = transform_to_dataset(test_sentences1)\n",
    " \n",
    "print(len(X_train1))     \n",
    "print(len(X_test1))         \n",
    "print(X_train1[0])\n",
    "print(y_train1[0])\n",
    "\n",
    " \n",
    "X_train, y_train = transform_to_dataset(training_sentences)\n",
    "X_test, y_test = transform_to_dataset(test_sentences)\n",
    " \n",
    "print(len(X_train))     \n",
    "print(len(X_test))         \n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "# 2935\n",
    "# 979\n",
    "# [{'word': 'Pierre' ...\n",
    "# ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn-crfsuite in /home/daniel/.local/lib/python3.7/site-packages (0.3.6)\n",
      "Requirement already satisfied: tabulate in /home/daniel/.local/lib/python3.7/site-packages (from sklearn-crfsuite) (0.8.7)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /home/daniel/.local/lib/python3.7/site-packages (from sklearn-crfsuite) (0.9.7)\n",
      "Requirement already satisfied: tqdm>=2.0 in /home/daniel/.local/lib/python3.7/site-packages (from sklearn-crfsuite) (4.46.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sklearn-crfsuite) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Funcion que permite forzar el uso de GPU cuando estan presentes\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "model = CRF()\n",
    "model1 = CRF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(keep_tempfiles=None)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(keep_tempfiles=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('el', 'da0ms0'), ('hombre', 'ncms000'), ('bajo', 'aq0ms0'), ('canta', 'ncms000'), ('bajo', 'aq0ms0'), ('el', 'da0ms0'), ('puente', 'ncms000'), ('rojo', 'aq0ms0'), ('en', 'sps00'), ('Sao', 'np0000l'), ('Paulo', 'np0000o'), ('en', 'sps00'), ('la', 'da0fs0'), ('escalera', 'ncfs000'), ('baja', 'aq0fs0')]\n",
      "[('The', 'AT'), ('small', 'JJ'), ('man', 'NN'), ('sign', 'NN'), ('under', 'IN'), ('the', 'AT'), ('red', 'JJ'), ('bridge', 'NN'), ('in', 'IN'), ('Sao', 'NP'), ('Paulo', 'NP'), ('in', 'IN'), ('the', 'AT'), ('small', 'JJ'), ('stairs', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "sentence = ['el', 'hombre', 'bajo','canta', 'bajo', 'el', 'puente', 'rojo','en','Sao','Paulo','en','la','escalera', 'baja']\n",
    "def pos_tag(sentence):\n",
    "    sentence_features = [features(sentence, index) for index in range(len(sentence))]\n",
    "    return list(zip(sentence, model.predict([sentence_features])[0]))\n",
    "\n",
    "print(pos_tag(sentence))\n",
    "\n",
    "sentence1 = ['The', 'small', 'man','sign', 'under', 'the', 'red', 'bridge','in','Sao','Paulo','in','the','small', 'stairs']\n",
    "def pos_tag1(sentence):\n",
    "    sentence_features = [features(sentence, index) for index in range(len(sentence))]\n",
    "    return list(zip(sentence, model1.predict([sentence_features])[0]))\n",
    " \n",
    "print(pos_tag1(sentence1))  # [('I', 'PRP'), ('am', 'VBP'), ('Bob', 'NNP'), ('!', '.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7679851675219151\n",
      "0.697530289391729\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    " \n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.flat_accuracy_score(y_test, y_pred))\n",
    " \n",
    "# 0.9602683593122289\n",
    "\n",
    " \n",
    "y_pred1 = model1.predict(X_test1)\n",
    "print(metrics.flat_accuracy_score(y_test1, y_pred1))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sps00', 'da0mp0', 'ncmp000', 'sps00', 'ncmp000', 'aq0mp0', 'Fc', 'vais3s0', 'dn0cp0', 'ncfp000', 'aq0fp0', 'rg', 'spcms', 'Fe', 'np0000a', 'Fe', 'pr0cn000', 'pp3msa00', 'vmis3p0', 'rg', 'sps00', 'vmn0000', 'aq0cp0', 'ncmp000', 'sps00', 'dp3cs0', 'ncfs000', 'Fp']\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&COMPARAMOS\n",
      "['sps00', 'da0mp0', 'ncmp000', 'sps00', 'ncmp000', 'ncmp000', 'Fc', 'vais3s0', 'dn0cp0', 'ncfp000', 'ncfp000', 'rg', 'spcms', 'Fe', 'np0000a', 'Fe', 'pr0cn000', 'ncms000', 'vmis3p0', 'cs', 'sps00', 'vmn0000', 'ncfp000', 'ncmp000', 'sps00', 'dp3cs0', 'ncfs000', 'Fp']\n",
      "['pi0ms000', 'sps00', 'da0mp0', 'Z', 'nccp000', 'vmis3s0', 'sps00', 'da0fs0', 'ncfs000', 'Fc', 'cc', 'da0fs0', 'ncfs000', 'aq0fs0', 'vmip3s0', 'aq0msp', 'da0ms0', 'ncms000', 'sps00', 'di0fs0', 'ncfs000', 'sps00', 'vmn0000', 'da0mp0', 'ncmp000', 'Fp']\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&COMPARAMOS\n",
      "['np0000o', 'sps00', 'da0mp0', 'Z', 'nccp000', 'vmis3s0', 'sps00', 'da0fs0', 'ncfs000', 'Fc', 'cc', 'da0fs0', 'ncfs000', 'aq0fs0', 'vmip3s0', 'aq0msp', 'da0ms0', 'ncms000', 'sps00', 'di0fs0', 'ncfs000', 'sps00', 'vmn0000', 'da0mp0', 'ncmp000', 'Fp']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "while i<= 1:\n",
    "    print(y_test[i])\n",
    "    print('&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&COMPARAMOS')\n",
    "    print(y_pred[i])\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################MODULES######################\n",
    "import sentencepiece as spm\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter.ttk import *\n",
    "\n",
    "#######################MODELS#######################\n",
    "# train sentencepiece model from `botchan.txt` and makes `m.model` and `m.vocab`\n",
    "# `m.vocab` is just a reference. not used in the segmentation.\n",
    "spm.SentencePieceTrainer.train('--input=botchan.txt --model_prefix=m --user_defined_symbols=<sep>,<cls> --vocab_size=2000')\n",
    "\n",
    "spm.SentencePieceTrainer.train('--input=tweets_clean.txt --model_prefix=m_word --model_type=word --user_defined_symbols=<sep>,<cls> --vocab_size=2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "def tokenizer(post=False):\n",
    "    select = combo.get()\n",
    "    text = inputText.get(\"1.0\",END)\n",
    "    sp = spm.SentencePieceProcessor()  \n",
    "    language = ''\n",
    "\n",
    "    if(select==\"Palabras (Español)\"):\n",
    "        sp.load('m_word.model')\n",
    "        language = 'es'\n",
    "    else:\n",
    "        sp.load('m.model')\n",
    "        \n",
    "        sp.piece_to_id('<sep>')\n",
    "        sp.piece_to_id('<cls>')\n",
    "        language = 'en'\n",
    "\n",
    "        \n",
    "    res = sp.encode_as_pieces(text)\n",
    "    \n",
    "    print(res)\n",
    "    if(post):return res,language\n",
    "    else:\n",
    "        res_postaggin=\"\"\n",
    "\n",
    "        for i in range(0,len(res)):\n",
    "            res_postaggin = res_postaggin + res[i] + \"\\n\"\n",
    "\n",
    "        outputText.configure(state='normal')\n",
    "        outputText.delete('1.0', END)\n",
    "        outputText.insert(\"insert\", res_postaggin)\n",
    "        outputText.configure(state='disabled')\n",
    "\n",
    "###################################################\n",
    "def postagging():\n",
    "        \n",
    "    res,language = tokenizer(post=True)\n",
    "    res1 = []    \n",
    "    \n",
    "    print(res)\n",
    "    \n",
    "    for i in range (0,len(res)):\n",
    "        print(res[i][0]=='▁')\n",
    "        print(res[i][0])\n",
    "        if(resel hombre bajo canta bajo el puente de color rojo en Sao Paulo en la escalera baja[i][0]=='▁' and len(res[i])>1): res1.append(res[i][1:])\n",
    "        else: res1.append(res[i])\n",
    "        res1[i].replace('▁', ' ')\n",
    "        \n",
    "        \n",
    "    if(language=='es'):\n",
    "        postag = pos_tag(res1)\n",
    "    else: postag = pos_tag1(res1)\n",
    "    res_postaggin=\"\"\n",
    "    \n",
    "    for i in range(0,len(res)):\n",
    "        res_postaggin = res_postaggin + postag[i][0] +\" | \"+ postag[i][1] + \"\\n\"\n",
    "    \n",
    "    outputText.configure(state='normal')\n",
    "    outputText.delete('1.0', END)\n",
    "    outputText.insert(\"insert\", res_postaggin)\n",
    "    outputText.configure(state='disabled')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-258f1b82efc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#######################GUI#########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokenizador - Procesamiento del Lenguaje Natural\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tk' is not defined"
     ]
    }
   ],
   "source": [
    "#######################GUI#########################\n",
    "window = Tk()\n",
    "\n",
    "window.title(\"Tokenizador - Procesamiento del Lenguaje Natural\")\n",
    "\n",
    "window.geometry('500x500')\n",
    "\n",
    "inputText = Text(window,height=14, width=25)\n",
    "inputText.grid(column=0, row=0)\n",
    "\n",
    "\n",
    "\n",
    "btn = Button(window, text=\"Tokenizer\",command=tokenizer)\n",
    "btn1 = Button(window, text=\"Postagging\",command=postagging)\n",
    "btn.grid(column=2, row=1)\n",
    "btn1.grid(column=3, row=1)\n",
    "\n",
    "combo = Combobox(window)\n",
    "combo['values']= (\"Personalizado (Inglés) \",\"Palabras (Español)\")\n",
    "combo.current(0) #set the selected item\n",
    "combo.grid(column=2, row=0)\n",
    "\n",
    "outputText = Text(window,height=14, width=25, state='disabled')\n",
    "outputText.grid(column=0, row=1)\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#el hombre bajo canta bajo el puente rojo en Sao Paulo en la escalera baja\n",
    "#I've not seen much info about how people in the UK can support the BLM movement here, so i've made a document which has links to how you can support black lives in the UK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
